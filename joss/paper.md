---
title: 'CliffordNumbers.jl: treating multivectors like primitive numeric types'
tags:
  - Julia
  - geometric algebra
  - Clifford algebra
authors:
  - name: Brandon S. Flores
    orcid: 0000-0003-0816-4491
    affiliation: 1
    corresponding: true
affiliations:
 - name: Department of Chemistry, Univesity of Wisconsin-Madison, USA
   index: 1
date: 19 May 2024
bibliography: paper.bib

---

# Summary

For decades, linear algebra libraries have been developed and intensely optimized to maximize
performance for a variety of important operations, including matrix multiplication and numerous
matrix factorizations. Although geometric algebra has gained popularity as an alternative convention
for the mathematics of physics, graphics, and other fields, particularly in the last 20 years, its
development on the software side has not been driven by an overarching shared need in the way linear 
algebra libraries have, instead being pushed forward by a significantly smaller community of both
researchers and enthusiasts.

`CliffordNumbers.jl` provides a high-performance implementation of commonly used operations in
geometric algebras of up to 6 dimensions without relying on a linear algebra library. In common
cases, the performance of this library allows for implementations of isometry composition or 
application with significantly greater speed than a matrix-based implementation for those spaces.

# Statement of need

Clifford algebras are ubiquitous throughout a number of domains, in particular, the physical 
sciences and computer graphics. In essence, they are algebras of orthonormality, and can be used to
model isometries: rotations, reflections, translations, and more. Several mathematical structures
commonly encountered in applied mathematics are isomorphic to Clifford algebras: probably the best 
known example is the *algebra of physical space (APS)*, $\text{Cl}_{3,0,0}\left(\mathbb{R}\right)$,
generated by the Pauli spin matrices. Its even subalgebra, 
$\text{Cl}^{+}_{3,0,0}\left(\mathbb{R}\right)$, is isomorphic to $\mathbb{H}$, the quaternions,
which are ubiquitous in computer graphics for providing concise and performant representations of
3D rotations. Similarly, the complex numbers, $\mathbb{C}$, are also isomorphic to a Clifford
algebra, the even subalgebra of 2D space, $\text{Cl}^{+}_{2,0,0}\left(\mathbb{R}\right)$.

Although Clifford algebras are well-understood mathematical objects, most work with them involves
matrix representations. Basis vectors of underlying space are represented by matrices whose matrix
products share the same properties as the product of the Clifford algebra, referred to as the
*Clifford product* or *geometric product*. Although matrix representations suffice for working with
a Clifford algebra, they can be opaque: for those unfamiliar with matrix representations, it can be
difficult to understand why 2×2 complex matrices are capable of modeling 3D space, or why the matrix
components are not directly interpretable. Matrix representations also obscure the grading of the
Clifford algebra, which is critical for understanding the geometric significance of operations in
the algebra.

This package uses a different approach, the *additive representation*: the behavior of the basis
vectors of the space is encoded in the implementation of the Clifford product. This representation
reveals the graded nature of the algebra and its link to exterior (Grassmann) algebras, whose
product, the *wedge product* ($\wedge$), also plays an important role in describing geometry. This
approach was initially developed by William Kingdon Clifford as a unification of Hermann Grassmann's
work on exterior algebras and William Rowan Hamilton's work on quaternions, but it lost to the
vector algebra formalism of Josiah Willard Gibbs and Oliver Heaviside and faded into obscurity as
a formalism.

David Hestenes revived the formalism as *geometric algebra*, the same term Clifford originally used
to describe his algebra. Although Clifford algebra and geometric algebra generally refer to the same
mathematical structure[^ca-ga-debate], the term "geometric algebra" is used here to emphasize the
alignment of the design of this package with the goals of geometric algebra community.

[^ca-ga-debate]: The exact definition of "geometric algebra" is not universally agreed upon. It is
generally agreed that a Clifford algebra over the real numbers is a geometric algebra, but there is
no consensus as to whether Clifford algebras over other fields constitute geometric algebras. In
this article, any such distinctions are unimportant.

# Implementation

`CliffordNumbers.jl` provides a generic implementation of geometric algebras of dimension only
limited by the machine it runs on. The `AbstractCliffordNumber{Q,T}` abstract type is a subtype of
the Julia Base `Number` type, and much of the semantics of the concrete subtypes of
`AbstractCliffordNumber{Q,T}` match those of other `Number` subtypes, including `Real`, 
`Complex{T}`, and the `Quaternion{T}` type provided by Quaternions.jl. This design decision was made
because the complex numbers and quaternions are both isomorphic to real Clifford algebras, and the
types provided by this library fill in the gaps for Clifford algebras with arbitrary signature.

This library does not depend on a linear algebra package. Unlike many other software implementations
of geometric algebras, this package does not use matrix representations to calculate the geometric
product or any related products. Instead, it uses the additive representation internally, where the
coefficients of an `AbstractCliffordNumber{Q,T}` instance are directly associated with the basis
blades of the algebra. Suprisingly, this allows for significant performance improvements over other
implementations that use matrix representations.

## Indexing

Although `AbstractCliffordNumber{Q,T}` instances behave like scalars, it is often necessary to
obtain individual components of an instance. The usual approach to indexing a data structure is with
integer indices, but this is disallowed: the exact ordering of coefficients in the backing `NTuple`
of an `AbstractCliffordNumber` is an implementation detail not to be exposed. Instead, indices
should always reference coefficients of the same basis blade, even if a particular data structure
constrains the coefficient to be zero or some other value.

To facilitate this, we provide the `BitIndex{Q}` type, which allows for the retrieval of the 
coefficient associated with a blade. This object tracks the basis blades using the least significant
bits of a `UInt` up to `dimension(Q)`, providing support for algebras with as many as 63 dimensions 
on 64-bit machines. The most significant bit is a sign bit, representing the parity of the
permutation: a zero bit represents a permutation with the same parity as a lexicographically ordered
wedge product of blades.

The `BitIndices{Q,C<:AbstractCliffordNumber{Q}}` type represents all of the indices of a type `C`
or an instance thereof. This allows for iterations over all indices of an `AbstractCliffordNumber`
at compile time, which is key to the fast implementation of various operations, including the
various products of geometric algebra.

If indexing elements of the underlying `NTuple` is desired, this conversion must be explicitly
performed with the constructor `Tuple(::AbstractCliffordNumber)`.

## Promotion

This package provides a variety of types which must all seamlessly integrate with each other.

Some promotion rules must be implemented as generated functions, as normal functions cannot achieve
type stability

## Multiplication

Geometric algebras admit several products. Aside from the geometric product, the wedge product
($\wedge$), regressive product ($\vee$), left contraction ($\rfloor$) and right contraction 
($\lfloor$), hold critical geometric significance. These products may be derived from the geometric
product by filtering out the products of specific basis blades, allowing them to go to zero. As an
example, the wedge product of two blades is zero if the blades share a linearly dependent component.
This filtering process is accomplished with a mask consisting of a `Tuple` of Boolean values,
leveraging the behavior of `false` as a multiplicative strong zero (`0 * NaN == 0`) and `true` as a
multiplicative identity.

To implement a product, we use a generated function, `CliffordNumbers.mul`, which takes three
arguments: two multivectors `x` and `y`, and a `CliffordNumbers.GradeFilter{S}` object which
incorporates the blade filtration process into the code generation. The type parameter `S` is a
`Symbol` matching the name of the function implementing the product. In addition, the `GradeFilter`
can be used to alter the signs of some multiplications: for instance, the dot product of two blades
$a$ and $b$ satisfies the following property:

The use of a generated function maximizes compile-time inference. All `BitIndex{Q}` objects
associated with the arguments are statically known from the types of the multivector inputs, and
therefore all of the sign changes and filtering can be incorporated into the function as constants
instead of being determined at runtime.

# Performance

For a worst-case comparison, we will provide a benchmark that compares the geometric product of two
arbitrary multivectors of APS, which have 8 `Float32` elements each, with the usual implementation 
involving multiplying 2×2 matrix representations with `Complex{Float32}` elements, stored in an
`SMatrix{2,2,Complex{Float32},4}` provided by the StaticArrays.jl package to maximize performance.

The code for each result is provided, and these comparisons were performed on an Intel Core
i5-13600K with 32 GB RAM:
```
julia> @benchmark $m1 * $m2
BenchmarkTools.Trial: 10000 samples with 1000 evaluations.
 Range (min … max):  2.548 ns … 208.505 ns  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     2.561 ns               ┊ GC (median):    0.00%
 Time  (mean ± σ):   2.596 ns ±   2.104 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%

              ▂ ▃ ▅ ▆ █ ▇▇ █ █ ▆ ▅ ▃ ▂                         
  ▂▂▁▂▁▃▁▄▁▅▁▆█▁█▁█▁█▁█▁██▁█▁█▁█▁█▁█▁██▁▆▁▅▁▄▁▃▁▃▂▁▂▁▂▁▂▁▂▁▂▂ ▄
  2.55 ns         Histogram: frequency by time        2.58 ns <

 Memory estimate: 0 bytes, allocs estimate: 0.

julia> @benchmark $c1 * $c2
BenchmarkTools.Trial: 10000 samples with 1000 evaluations.
 Range (min … max):  2.341 ns … 25.916 ns  ┊ GC (min … max): 0.00% … 0.00%
 Time  (median):     2.358 ns              ┊ GC (median):    0.00%
 Time  (mean ± σ):   2.378 ns ±  0.434 ns  ┊ GC (mean ± σ):  0.00% ± 0.00%

       ▇▅█▂▁                                                  
  ▂▂▃▆██████▄▄▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▂▂▂▁▂▂▁▁▁▁▁▂▂▂▂▁▂▂▂ ▃
  2.34 ns        Histogram: frequency by time        2.49 ns <

 Memory estimate: 0 bytes, allocs estimate: 0
```

To understand this result, we can analyze the algorithm for matrix multiplication and compare it to
the implementation of the geometric product provided by this package. We want to compare the total
number of operations on real numbers, so we must break down complex addition and multiplication into
its constituent real additions and multiplications. Complex addition is the straightforward addition
of real and imaginary coefficients, so it is two real additions:
```julia
+(z::Complex, w::Complex) = Complex(real(z) + real(w), imag(z) + imag(w))
```
The multiplication of two complex numbers consists of 4 multiplications and 2 additions:
```julia
*(z::Complex, w::Complex) = Complex(real(z) * real(w) - imag(z) * imag(w),
                                    real(z) * imag(w) + imag(z) * real(w))
```
The multiplication of a pair of 2×2 matrices consists of 4 sets of dot products between rows of the
first matrix and columns of the second. These dot products consist of two complex multiplications
and a complex addition, so in total there are 8 complex multiplications and 4 complex additions,
which total 32 real multiplications and 24 real additions.

In general, calculating the geometric product of two dense multivectors of an algebra of $d$ 
dimensions involves $2^{2d}$ multiplications and $2^{2d} - 2^d$ additions. Rephrased in terms of the
the number of elements of the multivectors, $n = 2^d$, the geometric product requires $d^2$
multiplications and $d\left(d - 1\right)$ additions. In the case of APS, a 3D algebra, this works
out to 64 multiplications and 56 additions.

It might be surprising that the geometric product as implemented with the additive representation
is slightly faster than matrix multiplication, despite the larger number of operations and identical
number of scalar components. The reason for this is that the geometric products in the additive
represenations are more amenable to SIMD optimization than matrix multiplication is. For comparison,
we provide the x86 assembly of both operations:
```
julia> @code_native c1*c2   # Geometric product
        .text
        .file   "*"
        .globl  "julia_*_3813"                  # -- Begin function julia_*_3813
        .p2align        4, 0x90
        .type   "julia_*_3813",@function
"julia_*_3813":                         # @"julia_*_3813"
# %bb.0:                                # %top
        push    rbp
        vmovupd ymm1, ymmword ptr [rdx]
        vbroadcastss    ymm0, dword ptr [rsi + 4]
        vbroadcastss    ymm3, dword ptr [rsi + 8]
        vbroadcastss    ymm4, dword ptr [rsi]
        vbroadcastss    ymm6, dword ptr [rsi + 12]
        mov     rbp, rsp
        mov     rax, rdi
        vpermilps       ymm2, ymm1, 177         # ymm2 = ymm1[1,0,3,2,5,4,7,6]
        vpermilpd       ymm5, ymm1, 5           # ymm5 = ymm1[1,0,3,2]
        vpermpd ymm8, ymm1, 78                  # ymm8 = ymm1[2,3,0,1]
        vmulps  ymm0, ymm0, ymm2
        vmulps  ymm3, ymm3, ymm5
        vxorps  xmm5, xmm5, xmm5
        vfmadd231ps     ymm5, ymm1, ymm4        # ymm5 = (ymm1 * ymm4) + ymm5
        vpermilps       ymm4, ymm1, 27          # ymm4 = ymm1[3,2,1,0,7,6,5,4]
        vpermpd ymm1, ymm1, 27                  # ymm1 = ymm1[3,2,1,0]
        vaddps  ymm0, ymm5, ymm0
        vmulps  ymm5, ymm6, ymm4
        vbroadcastss    ymm6, dword ptr [rsi + 16]
        vaddps  ymm7, ymm0, ymm3
        vsubps  ymm0, ymm0, ymm3
        vbroadcastss    ymm3, dword ptr [rsi + 20]
        vmulps  ymm6, ymm8, ymm6
        vsubps  ymm7, ymm7, ymm5
        vaddps  ymm0, ymm0, ymm5
        vmulps  ymm2, ymm3, ymm2
        vbroadcastss    ymm3, dword ptr [rsi + 24]
        vblendps        ymm0, ymm7, ymm0, 170           # ymm0 = ymm7[0],ymm0[1],ymm7[2],ymm0[3],ymm7[4],ymm0[5],ymm7[6],ymm0[7]
        vbroadcastss    ymm7, dword ptr [rsi + 28]
        vaddps  ymm5, ymm0, ymm6
        vsubps  ymm0, ymm0, ymm6
        vmulps  ymm1, ymm3, ymm1
        vpermpd ymm2, ymm2, 78                  # ymm2 = ymm2[2,3,0,1]
        vsubps  ymm3, ymm5, ymm2
        vaddps  ymm0, ymm0, ymm2
        vmulps  ymm2, ymm7, ymm4
        vblendps        ymm0, ymm3, ymm0, 102           # ymm0 = ymm3[0],ymm0[1,2],ymm3[3,4],ymm0[5,6],ymm3[7]
        vsubps  ymm3, ymm0, ymm1
        vaddps  ymm0, ymm0, ymm1
        vpermpd ymm1, ymm2, 78                  # ymm1 = ymm2[2,3,0,1]
        vsubps  ymm2, ymm3, ymm1
        vaddps  ymm0, ymm0, ymm1
        vblendps        ymm0, ymm2, ymm0, 204           # ymm0 = ymm2[0,1],ymm0[2,3],ymm2[4,5],ymm0[6,7]
        vmovups ymmword ptr [rdi], ymm0
        pop     rbp
        vzeroupper
        ret
.Lfunc_end0:
        .size   "julia_*_3813", .Lfunc_end0-"julia_*_3813"
                                        # -- End function
        .section        ".note.GNU-stack","",@progbits
```
```
julia> @code_native m1*m2   # Matrix multiply
        .text
        .file   "*"
        .globl  "julia_*_3811"                  # -- Begin function julia_*_3811
        .p2align        4, 0x90
        .type   "julia_*_3811",@function
"julia_*_3811":                         # @"julia_*_3811"
# %bb.0:                                # %top
        push    rbp
        vmovdqu xmm0, xmmword ptr [rsi]
        mov     rax, rdi
        vmovsd  xmm2, qword ptr [rdx]           # xmm2 = mem[0],zero
        vmovss  xmm4, dword ptr [rdx + 16]      # xmm4 = mem[0],zero,zero,zero
        mov     rbp, rsp
        vpextrq rcx, xmm0, 1
        vmovq   rdi, xmm0
        vshufps xmm5, xmm2, xmm4, 0             # xmm5 = xmm2[0,0],xmm4[0,0]
        shld    rcx, rdi, 32
        vmovq   xmm1, rcx
        vpbroadcastq    xmm1, xmm1
        vpblendd        xmm3, xmm0, xmm1, 2             # xmm3 = xmm0[0],xmm1[1],xmm0[2,3]
        vpblendd        xmm6, xmm0, xmm1, 3             # xmm6 = xmm1[0,1],xmm0[2,3]
        vpshufd xmm0, xmm0, 204                 # xmm0 = xmm0[0,3,0,3]
        vpbroadcastq    xmm3, xmm3
        vmulps  xmm3, xmm3, xmm5
        vpshufd xmm5, xmm6, 204                 # xmm5 = xmm6[0,3,0,3]
        vmovss  xmm6, dword ptr [rdx + 20]      # xmm6 = mem[0],zero,zero,zero
        vshufps xmm7, xmm2, xmm6, 5             # xmm7 = xmm2[1,1],xmm6[0,0]
        vmulps  xmm5, xmm5, xmm7
        vinsertps       xmm7, xmm2, xmm4, 32    # xmm7 = xmm2[0,1],xmm4[0],xmm2[3]
        vshufps xmm2, xmm2, xmm6, 193           # xmm2 = xmm2[1,0],xmm6[0,3]
        vinsertps       xmm7, xmm7, xmm6, 48    # xmm7 = xmm7[0,1,2],xmm6[0]
        vinsertps       xmm2, xmm2, xmm4, 48    # xmm2 = xmm2[0,1,2],xmm4[0]
        vmovups xmm4, xmmword ptr [rdx + 8]
        vmovss  xmm6, dword ptr [rdx + 28]      # xmm6 = mem[0],zero,zero,zero
        vmulps  xmm0, xmm0, xmm2
        vmulps  xmm1, xmm7, xmm1
        vmovups xmm2, xmmword ptr [rsi + 16]
        vsubps  xmm3, xmm3, xmm5
        vmovss  xmm5, dword ptr [rsi + 20]      # xmm5 = mem[0],zero,zero,zero
        vaddps  xmm0, xmm1, xmm0
        vmovups xmm1, xmmword ptr [rdx + 12]
        vblendps        xmm5, xmm2, xmm5, 3             # xmm5 = xmm5[0,1],xmm2[2,3]
        vpermilps       xmm2, xmm2, 136         # xmm2 = xmm2[0,2,0,2]
        vpermilps       xmm5, xmm5, 204         # xmm5 = xmm5[0,3,0,3]
        vshufps xmm6, xmm1, xmm6, 0             # xmm6 = xmm1[0,0],xmm6[0,0]
        vshufps xmm1, xmm4, xmm1, 240           # xmm1 = xmm4[0,0],xmm1[3,3]
        vfmadd231ps     xmm0, xmm5, xmm1        # xmm0 = (xmm5 * xmm1) + xmm0
        vfmsub231ps     xmm3, xmm5, xmm6        # xmm3 = (xmm5 * xmm6) - xmm3
        vfmadd231ps     xmm0, xmm2, xmm6        # xmm0 = (xmm2 * xmm6) + xmm0
        vfmsub231ps     xmm3, xmm2, xmm1        # xmm3 = (xmm2 * xmm1) - xmm3
        vpmovzxdq       ymm0, xmm0              # ymm0 = xmm0[0],zero,xmm0[1],zero,xmm0[2],zero,xmm0[3],zero
        vpmovzxdq       ymm1, xmm3              # ymm1 = xmm3[0],zero,xmm3[1],zero,xmm3[2],zero,xmm3[3],zero
        vpsllq  ymm0, ymm0, 32
        vpblendd        ymm0, ymm1, ymm0, 170           # ymm0 = ymm1[0],ymm0[1],ymm1[2],ymm0[3],ymm1[4],ymm0[5],ymm1[6],ymm0[7]
        vmovdqu ymmword ptr [rax], ymm0
        pop     rbp
        vzeroupper
        ret
.Lfunc_end0:
        .size   "julia_*_3811", .Lfunc_end0-"julia_*_3811"
                                        # -- End function
        .section        ".note.GNU-stack","",@progbits
```
The most significant difference is the use of Intel AVX's 256-bit YMM registers in the geometric 
product implementation using the additive representation, as opposed to matrix multiplication, which 
uses the SSE 128-bit XMM registers. Matrix multiplication involves the calculation of dot products 
between rows of the first matrix and columns of the second matrix, and these rows and columns 
consist of two `Complex{Float32}` elements, each 64 bits long, for a total of 128 bits. In the 
geometric product implementation, the entire multivector can be operated on simultaneously, since a
`CliffordNumber{VGA(3),Float32,8}` is already 256 bits long, and the multiplication is implemented 
as a series of vector element permutations, scalar multiplications, and vector additions.

In practice, isometries of the space are represented by unit $k$-versors, the geometric product of 
$k$ 1-blades. These necessarily only contain elements of either even or odd grades, meaning that 
only half as many coefficients are present. On top of this, the `KVector{K,Q,T,L}` data type can be
used to represent $k$-blades, and these only have `binomial(dimension(Q), K)` elements. Therefore,
the speedup can be significantly larger. In general, for multivectors of even or odd grade of an
algebra of $n$ dimensions, $2^{2\left(d-1\right)}$ multiplications and 
$2^{2\left(d-1\right)} - 2^{d-1}$ additions are needed, which works out to 16 multiplications and 12
additions in the 3D algebra of physical space. As expected, this is identical to quaternion
multiplication.

# Examples

# Development roadmap

The next major development milestones for `CliffordNumbers.jl` will include 

# Dedication and acknowledgements

The author dedicates this software and article to his best friends, Dr. Michael E. Davies, Kristel
M. Forlano, and Danica G. Gressel.

The author acknowledges the community at [bivector.net](https://www.bivector.net), especially 
members of the affiliated Discord server, in contributing their collective knowledge of geometric
algebras, their applications, and software implementations. In particular he would like to
specifically acknowledge the following community members:
- sudgylacmoe, YouTuber and creator of the video A Swift Introduction to Geometric Algebra, who also
provided critical counterexamples to common assumptions in geometric algebra that informed the 
documentation of this software.
- Joseph Wilson (Jollywatt), author of another Julia geometric algebra package, GeometricAlgebra.jl.

# References
